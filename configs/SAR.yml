TrainReader:
  dataloader: dataset,BatchBalancedDataset
  select_data: 'ArT_train-LSVT_train-MTWI_train-RCTW17_train-ReCTS_train'
  batch_ratio: '0.2-0.2-0.2-0.2-0.2'
  total_data_usage_ratio: 1.0
  padding: True
  augment: False
  batch_size: 128
  shuffle: True
  num_workers: 16
  lmdb_sets_dir: /LegendStart/text_recognition_toolbox/datasets/scene_trainset

EvalReader:
  dataloader: dataset,evaldataloader
  select_data: '/'
  batch_size: 128
  padding: True
  shuffle: True
  num_workers: 16
  lmdb_sets_dir: /LegendStart/text_recognition_toolbox/datasets/scene_testset

TestReader:
  dataloader: dataset,evaldataloader
  select_data: '/'
  batch_size: 2
  padding: True
  shuffle: True
  num_workers: 0
  lmdb_sets_dir: 

Global:
  algorithm: SAR
  use_gpu: True
  gpu_num: '0'
  device: cuda:0
  num_iters: 800000
  highest_acc_save_type: False
  data_filtering_off: False
  resumed_optimizer: False
  batch_max_length: 50
  print_batch_step: 10
  save_model_dir: output/SAR
  eval_batch_step: 2000
  image_shape: [1, 32, 256]
  character_type: ch
  loss_type: attn
  use_space_char: false
  character_dict_path: /LegendStart/deep-text-recognition-benchmark/scene_attach_train_set/lgconti_keys_20200817.txt
  seed: 1234
  pretrain_weights:
  save_inference_dir:
  infer_img:


Architecture:
  function: networks.SAR,SAR
  layers: [1, 2, 5, 3]
 
SeqRNN:
  input_size: 512
  en_hidden_size: 256
  de_hidden_size: 256
    
Loss:
  function: loss,AttnLoss
  blank_idx: 0

Optimizer:
  function: adam
  base_lr: 0.001
  momentum: 0.9
  weight_decay: 1.0e-4
  lr_decay_epoch: 10
  max_epoch: 1000
