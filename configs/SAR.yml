TrainReader:
  dataloader: dataset,BatchBalancedDataset
  select_data: 'hetong_train'
  batch_ratio: '1.0'
  total_data_usage_ratio: 1.0
  padding: True
  augment: True
  batch_size: 256
  shuffle: True
  num_workers: 8
  lmdb_sets_dir: /LegendContinue/text_recognition/deep-text-recognition-benchmark/scene_attach_train_set

EvalReader:
  dataloader: dataset,evaldataloader
  select_data: 'hetong_test'
  batch_size: 256
  padding: True
  shuffle: True
  num_workers: 8
  lmdb_sets_dir: /LegendContinue/text_recognition/deep-text-recognition-benchmark/scene_attach_test_set/

TestReader:
  dataloader: dataset,evaldataloader
  select_data: '/'
  batch_size: 2
  padding: True
  shuffle: True
  num_workers: 0
  lmdb_sets_dir: 

Global:
  algorithm: SAR
  use_gpu: True
  gpu_num: '2'
  device: cuda:0
  num_iters: 800000
  highest_acc_save_type: False
  data_filtering_off: False
  resumed_optimizer: False
  batch_max_length: 50
  print_batch_step: 10
  save_model_dir: output/SAR/hetong_model
  eval_batch_step: 2000
  image_shape: [1, 32, 480]
  character_type: ch
  loss_type: attn
  use_space_char: False
  character_dict_path: /LegendContinue/text_recognition/deep-text-recognition-benchmark/scene_attach_train_set_keys/lgconti_keys_20200817.txt
  seed: 1234
  pretrain_weights: /LegendContinue/text_recognition/text_recognition_toolbox/output/SAR/common_doc_model/iter_48000.pth
  is_train: True
  save_inference_dir: 
  infer_img:


Architecture:
  function: networks.SAR,SAR
  layers: [1, 2, 5, 3]
 
SeqRNN:
  input_size: 512
  en_hidden_size: 256
  de_hidden_size: 256
    
Loss:
  function: loss,AttnLoss
  blank_idx: 0

Optimizer:
  function: adam
  base_lr: 0.001
  momentum: 0.9
  weight_decay: 1.0e-4
  lr_decay_epoch: 10
  max_epoch: 1000
